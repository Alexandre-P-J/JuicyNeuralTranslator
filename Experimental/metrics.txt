//////////////////////////////////////////
/////////////// FINETUNING ///////////////
//////////////////////////////////////////
# ORIGINAL EN-ES
SciELO Test
{'eval_loss': 1.3268274068832397, 'eval_BLEU': 40.1954, 'eval_chr-F': 67.1326, 'eval_gen_len': 40.2621, 'eval_runtime': 7380.1097, 'eval_samples_per_second': 11.282, 'eval_steps_per_second': 0.705}
Tatoeba challenge
{'eval_loss': 0.6677169799804688, 'eval_BLEU': 56.9578, 'eval_chr-F': 73.6682, 'eval_gen_len': 9.8371, 'eval_runtime': 403.7111, 'eval_samples_per_second': 41.076, 'eval_steps_per_second': 2.569}
JRC-Acquis Last Eval
{'eval_loss': 0.7985895872116089, 'eval_BLEU': 55.2525, 'eval_chr-F': 73.6, 'eval_gen_len': 36.9017, 'eval_runtime': 11036.3434, 'eval_samples_per_second': 9.151, 'eval_steps_per_second': 0.572}

# FINE-TUNED (SciELO) EN-ES
Last SciELO epoch Eval
{'eval_loss': 1.1000547409057617, 'eval_BLEU': 43.0387, 'eval_chr-F': 68.9894, 'eval_gen_len': 40.3343, 'eval_runtime': 7479.1499, 'eval_samples_per_second': 11.133, 'eval_steps_per_second': 0.696}
SciELO Test
{'eval_loss': 1.1033543348312378, 'eval_BLEU': 43.0197, 'eval_chr-F': 68.9007, 'eval_gen_len': 40.3101, 'eval_runtime': 7688.0882, 'eval_samples_per_second': 10.83, 'eval_steps_per_second': 0.677}
Tatoeba challenge
{'eval_loss': 0.7542015910148621, 'eval_BLEU': 49.8269, 'eval_chr-F': 68.939, 'eval_gen_len': 10.1284, 'eval_runtime': 435.6015, 'eval_samples_per_second': 38.069, 'eval_steps_per_second': 2.381}

//////////////////////////////////////////
//////////////// TRANSFER ////////////////
//////////////////////////////////////////
ES-EN model Huggingface:
TATOEBA CA-EN:
{'eval_loss': 2.3259971141815186, 'eval_BLEU': 9.6952, 'eval_chr-F': 28.3868, 'eval_gen_len': 14.0098, 'eval_runtime': 71.6396, 'eval_samples_per_second': 22.767, 'eval_steps_per_second': 1.424}
TATOEBA ES-EN:
{'eval_loss': 0.6026059985160828, 'eval_BLEU': 60.6793, 'eval_chr-F': 74.9145, 'eval_gen_len': 10.2411, 'eval_runtime': 416.2852, 'eval_samples_per_second': 39.836, 'eval_steps_per_second': 2.491}

CA-EN model Huggingface:
TATOEBA CA-EN:
{'eval_loss': 0.9886807799339294, 'eval_BLEU': 48.7704, 'eval_chr-F': 65.7556, 'eval_gen_len': 9.4985, 'eval_runtime': 66.2353, 'eval_samples_per_second': 24.624, 'eval_steps_per_second': 1.54}
TATOEBA ES-EN:
{'eval_loss': 2.3238627910614014, 'eval_BLEU': 17.6634, 'eval_chr-F': 36.9217, 'eval_gen_len': 12.0808, 'eval_runtime': 1178.8446, 'eval_samples_per_second': 14.067, 'eval_steps_per_second': 0.88}

CA-EN transfer from ES-EN model:
TATOEBA CA-EN:
{'eval_loss': 0.7405405044555664, 'eval_BLEU': 51.0978, 'eval_chr-F': 67.7934, 'eval_gen_len': 9.5665, 'eval_runtime': 38.9187, 'eval_samples_per_second': 41.908, 'eval_steps_per_second': 2.621}
TATOEBA ES-EN:
{'eval_loss': 0.8239797949790955, 'eval_BLEU': 48.0979, 'eval_chr-F': 65.5349, 'eval_gen_len': 10.3163, 'eval_runtime': 445.4392, 'eval_samples_per_second': 37.228, 'eval_steps_per_second': 2.328}
